{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from io import StringIO\n",
    "import os\n",
    "import codecs\n",
    "import re \n",
    "import camelot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime,date,timedelta\n",
    "\n",
    "sectors = ['Livelihoods and basic needs', 'Protection, Gender & Inclusion', 'Health', 'WASH', 'Migration']\n",
    "\n",
    "# map sectors to naming convention used in \"IFRC GO Matrix\"\n",
    "sector_map = {'Livelihoods and basic needs': 'Livelihoods and basic needs',\n",
    "              'WASH': 'WASH',\n",
    "              'Health': 'Health',\n",
    "              'Protection, Gender & Inclusion': 'PGI',\n",
    "              'Migration': 'Migration'}\n",
    "\n",
    "keyword_map = {'CEA': 'CEA',\n",
    "             'RCCE': 'CEA',\n",
    "             'DRR': 'DRR',\n",
    "             'education': 'Education',\n",
    "             'PGI': 'PGI',\n",
    "             'shelter': 'Shelter',\n",
    "             'WASH': 'WASH',\n",
    "             'NSD': 'NSD',\n",
    "             'migration': 'Migration'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractTxtAndTables():\n",
    "    for country in os.listdir('Approved Plans'):\n",
    "#         # Test only on Cook Islands\n",
    "#         if country != 'Cook Islands':\n",
    "#             continue\n",
    "\n",
    "        for file in os.listdir('Approved Plans/'+country):\n",
    "\n",
    "            if file.startswith('MDR') and file.endswith('pdf'):\n",
    "                output_string = StringIO()\n",
    "                with open('Approved Plans/'+country+'/'+file, 'rb') as fh:\n",
    "                    \n",
    "                    # parse pages with landscape orientation\n",
    "                    parser = PDFParser(fh)\n",
    "                    doc = PDFDocument(parser)\n",
    "                    rsrcmgr = PDFResourceManager()\n",
    "                    device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
    "                    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "                    landscapepages = list()\n",
    "                    for ix, page in enumerate(PDFPage.create_pages(doc)):\n",
    "                        # only pages with landscape orientation\n",
    "                        if page.cropbox[2] < 800:\n",
    "                            continue\n",
    "                        interpreter.process_page(page)\n",
    "                        # count landscape page \n",
    "                        landscapepages.append(ix+1)\n",
    "                    \n",
    "                    landscapepages = str(landscapepages)\n",
    "                    landscapepages = landscapepages[1:-1]\n",
    "                    \n",
    "                    # find all tables in the landscape pages and create excel tables\n",
    "                    foundtables = camelot.read_pdf('Approved Plans/'+country+'/'+file, pages=landscapepages)\n",
    "                    for i in range(len(foundtables)):\n",
    "                        foundtables[i].to_excel('Approved Plans/'+country+'/'+'Table_test'+str(i)+'.xlsx')\n",
    "                    \n",
    "                    # save text of the landscape pages in txt\n",
    "                    file1 = codecs.open('Approved Plans/'+country+'/'+file.split('.')[0]+'.txt', \"w\", \"utf-8\")  # write mode\n",
    "                    file1.write(output_string.getvalue())\n",
    "                    file1.close()\n",
    "                    \n",
    "                    # parse first page and save corresponding text in txt\n",
    "                    parser = PDFParser(fh)\n",
    "                    doc = PDFDocument(parser)\n",
    "                    rsrcmgr = PDFResourceManager()\n",
    "                    device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
    "                    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "                    landscapepages = list()\n",
    "                    for ix, page in enumerate(PDFPage.create_pages(doc)):\n",
    "                        if ix>0:\n",
    "                            continue\n",
    "                        interpreter.process_page(page)\n",
    "                        \n",
    "                    file1 = codecs.open('Approved Plans/'+country+'/'+file.split('.')[0]+'_firstpage.txt', \"w\", \"utf-8\")  # write mode\n",
    "                    file1.write(output_string.getvalue())\n",
    "                    file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ParseTablesExtractActivities():\n",
    "    \n",
    "    for country in os.listdir('Approved Plans'):\n",
    "#         # Test only on Cook Islands\n",
    "#         if country != 'Cook Islands':\n",
    "#             continue\n",
    "\n",
    "        # merge all tables\n",
    "        table_all = pd.DataFrame()\n",
    "        for table in [x for x in os.listdir('Approved Plans/'+country) if x.endswith('xlsx')]:\n",
    "                table = pd.read_excel('Approved Plans/'+country+'/'+table)\n",
    "                table_all = pd.concat([table_all, table])\n",
    "        ncolraw = len(table_all.columns)\n",
    "        table_all = table_all.rename(columns={0: 'code', 1: 'text'})\n",
    "        table_all = table_all.reset_index()\n",
    "        \n",
    "        if table_all.empty:\n",
    "            print(country, 'missing tables')\n",
    "            continue\n",
    "\n",
    "        # specify sector in each table entry\n",
    "        table_all['sector'] = ''\n",
    "        sector_active = ''\n",
    "        for ix, row in table_all.iterrows():\n",
    "            for sector in sectors:\n",
    "                search = sector + ' Output'\n",
    "                try:\n",
    "                    if search.lower() in row.text.lower() and 'P&B' in row.code:\n",
    "                        sector_active = sector\n",
    "                    else:\n",
    "                        continue\n",
    "                except:\n",
    "                    pass\n",
    "            table_all.at[ix, 'sector'] = sector_active\n",
    "        # print results\n",
    "#         for sector in table_all.sector.unique():\n",
    "#             print(table_all[table_all.sector == sector].head())\n",
    "\n",
    "        # get activities\n",
    "        table_activities = table_all.dropna(subset=['code'])\n",
    "        table_activities = table_activities[table_activities.code.str.contains('AP')]\n",
    "        \n",
    "        # if some activities don't have a sector, drop\n",
    "        table_activities = table_activities[table_activities['sector']!='']\n",
    "        \n",
    "        if table_activities.empty:\n",
    "            print('ERROR ({}): no activities found, skipping country'.format(country))\n",
    "            continue\n",
    "            \n",
    "        table_activities.text = table_activities.text.apply(lambda x: re.sub(r'\\nx', '', str(x)))\n",
    "        table_activities.text = table_activities.text.apply(lambda x: re.sub(r'\\n', ' ', str(x)))\n",
    "        \n",
    "        # get activity date (month number)\n",
    "        table_activities['activity_start'] = 0\n",
    "        table_activities['activity_end'] = 0\n",
    "        for ix, row in table_activities.iterrows():\n",
    "            activity_start, activity_end = 0, 0\n",
    "            for i in range(2, ncolraw-1):\n",
    "                if isinstance(row[i], str) and 'x' in row[i]:\n",
    "                    if activity_start == 0:\n",
    "                        activity_start = i-1\n",
    "                    activity_end = i-1\n",
    "            table_activities.at[ix, 'activity_start'] = activity_start\n",
    "            table_activities.at[ix, 'activity_end'] = activity_end\n",
    "\n",
    "        # load output_data\n",
    "        output_data = pd.read_excel('matrix_filled.xlsx')\n",
    "\n",
    "        # fill output_data\n",
    "        for ix, row in table_activities.iterrows():\n",
    "            data_entry = pd.Series({'Country': country,\n",
    "                                    sector_map[row['sector']]: row['text'],\n",
    "                                    'Planned activity start date': row['activity_start'],\n",
    "                                    'Planned activity end date': row['activity_end']\n",
    "                                   })\n",
    "            output_data = output_data.append(data_entry, ignore_index=True)\n",
    "            \n",
    "            for key, target in keyword_map.items():\n",
    "                if key in row['text'] and target != sector_map[row['sector']]:\n",
    "                    data_entry = pd.Series({'Country': country,\n",
    "                                            target: row['text'],\n",
    "                                            'Planned activity start date': row['activity_start'],\n",
    "                                            'Planned activity end date': row['activity_end']})\n",
    "                    output_data = output_data.append(data_entry, ignore_index=True)\n",
    "\n",
    "        # save output data\n",
    "        output_data.to_excel('matrix_filled.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ParseTxtExtractExtraInfoSector():\n",
    "    \n",
    "    sectors_txt = sectors\n",
    "    sectors_txt.append('Health and WASH') # some plans (e.g. Philippines) merge the two sectors\n",
    "    \n",
    "    for country in os.listdir('Approved Plans'):\n",
    "#         # Test only on Cook Islands\n",
    "#         if country != 'Cook Islands':\n",
    "#             continue\n",
    "\n",
    "        for file in os.listdir('Approved Plans/'+country):\n",
    "\n",
    "            if file.startswith('MDR') and file.endswith('txt') and 'firstpage' not in file:\n",
    "                \n",
    "                # read txt file\n",
    "                file1 = codecs.open('Approved Plans/' + country + '/' + file.split('.')[0] + '.txt', \"r\",\n",
    "                                    \"utf-8\")  # write mode\n",
    "                text = file1.read()\n",
    "                \n",
    "                # get detailed operational plan\n",
    "                text = re.split(r\"(.*)Detailed Operational Plan\", text, re.MULTILINE | re.DOTALL)[-1]\n",
    "                \n",
    "                # loop over sectors and extract extra info\n",
    "                info_sectors = {}\n",
    "                \n",
    "                for sector in sectors_txt:\n",
    "                    if sector == 'Protection, Gender & Inclusion':\n",
    "                        sector_re = 'Protection, Gender and Inclusion'\n",
    "                    elif sector == 'WASH':\n",
    "                        sector_re = 'Water, sanitation and hygiene'\n",
    "                    else:\n",
    "                        sector_re = sector\n",
    "                        \n",
    "                    text_sector = re.split(sector_re+' \\nPeople', text, re.MULTILINE | re.DOTALL)\n",
    "                    \n",
    "                    if len(text_sector)==1:\n",
    "                        continue\n",
    "                    text_sector = text_sector[1]\n",
    "                    \n",
    "                    for line in re.split(r\"\\n\", text_sector, re.MULTILINE | re.DOTALL)[:10]:\n",
    "                        if 'targeted:' in line:\n",
    "                            if re.findall(r\"[0-9,]+\", line) == []:\n",
    "                                print(country+' has no target people')\n",
    "                                peop_target = '-'    \n",
    "                            else:\n",
    "                                peop_target = re.findall(r\"[0-9,]+\", line)[0]\n",
    "                        if 'Requirements (CHF):' in line:\n",
    "                            if re.findall(r\"[0-9,]+\", line) == []:\n",
    "                                print(country+' has no target people')\n",
    "                                budget = '-'    \n",
    "                            else:\n",
    "                                budget = re.findall(r\"[0-9,]+\", line)[0]\n",
    "                            \n",
    "                    if sector != 'Health and WASH':\n",
    "                        info_sectors[sector] = {'Number of targeted (if applicable)': peop_target, 'Funding': budget}\n",
    "                    else:\n",
    "                        info_sectors['Health'] = {'Number of targeted (if applicable)': peop_target, 'Funding': budget}\n",
    "                        info_sectors['WASH'] = {'Number of targeted (if applicable)': peop_target, 'Funding': budget}\n",
    "                    \n",
    "        # load output_data\n",
    "        output_data = pd.read_excel('matrix_filled.xlsx')\n",
    "\n",
    "        # fill output_data\n",
    "        for sector, infos in info_sectors.items():\n",
    "            for field, number in infos.items():\n",
    "                output_data.at[output_data[output_data['Country']==country][~output_data[sector_map[sector]].isna()].index, field] = number\n",
    "\n",
    "        # save output data\n",
    "        output_data.to_excel('matrix_filled.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ParseFirstPage():\n",
    "    \n",
    "    for country in os.listdir('Approved Plans'):\n",
    "#         # Test only on Cook Islands\n",
    "#         if country != 'Cook Islands':\n",
    "#             continue\n",
    "\n",
    "        for file in os.listdir('Approved Plans/'+country):\n",
    "\n",
    "            if file.startswith('MDR') and file.endswith('.txt') and 'firstpage' not in file:\n",
    "                \n",
    "                # read txt file\n",
    "                file1 = codecs.open('Approved Plans/' + country + '/' + file.split('.')[0] + '_firstpage.txt', \"r\",\n",
    "                                    \"utf-8\")  # write mode\n",
    "                text = file1.read()\n",
    "                \n",
    "                text = text.replace('  ', ' ')\n",
    "                text = text.replace('\\n', ' ')\n",
    "                text = text.replace(' in '+country, '')\n",
    "                \n",
    "                matches = re.findall(r\"(?<=Red Cross and Red Crescent Movement partners actively involved in the operation:)(.*)Other partner organizations actively involved in the operation:\", text)\n",
    "                if matches == []:\n",
    "                    matches = re.findall(r\"(?<=Red Cross Red Crescent Movement partners actively involved in the operation:)(.*)Other partner organizations actively involved in the operation:\", text)\n",
    "                if matches == []:\n",
    "                    matches = re.findall(r\"(?<=Red Cross and Red Crescent partners actively involved in the operation:)(.*)Other partner organizations actively involved in the operation:\", text)\n",
    "                \n",
    "                if matches == []:\n",
    "                    print(text)\n",
    "                    print(country, 'none')\n",
    "                else:\n",
    "                    RCRC_partners = matches[0]\n",
    "                    field = 'In country Partner NS'\n",
    "                    \n",
    "                # find start date\n",
    "                matches = re.findall(r\"[0-9]{2}/[0-9]{2}/[0-9]{4}\", text)\n",
    "                matches.extend(re.findall(r\"[0-9]{2} [A-Z][a-z]+ [0-9]{4}\", text))\n",
    "                if matches == []:\n",
    "                    print(country, 'no dates found')\n",
    "                else:\n",
    "                    dates = []\n",
    "                    for match in matches:\n",
    "                        try:\n",
    "                            dates.append(datetime.strptime(match, '%d/%m/%Y'))\n",
    "                        except:\n",
    "                            try:\n",
    "                                dates.append(datetime.strptime(match, '%d %B %Y'))\n",
    "                            except:\n",
    "                                pass\n",
    "                    dates.sort()\n",
    "                    # take the most recent one, but not in the future\n",
    "                    begin_date = dates[-1]\n",
    "                    i = 2\n",
    "                    while begin_date > datetime.today():\n",
    "                        try:\n",
    "                            begin_date = dates[-i]\n",
    "                            i += 1\n",
    "                        except:\n",
    "                            break\n",
    "                    \n",
    "                    # load output_data\n",
    "                    output_data = pd.read_excel('matrix_filled.xlsx')\n",
    "\n",
    "                    # fill output_data\n",
    "                    output_data.at[output_data[output_data['Country']==country].index, field] = RCRC_partners\n",
    "                    output_data.at[output_data[output_data['Country']==country].index, 'Plan start date'] = begin_date\n",
    "\n",
    "                    # save output data\n",
    "                    output_data.to_excel('matrix_filled.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdjustDates():\n",
    "    \n",
    "    # load output_data\n",
    "    output_data = pd.read_excel('matrix_filled.xlsx')\n",
    "    output_data['Plan start date'] = pd.to_datetime(output_data['Plan start date'])\n",
    "    output_data['Planned activity start date'] = output_data['Planned activity start date'].astype(object)\n",
    "    output_data['Planned activity end date'] = output_data['Planned activity end date'].astype(object)\n",
    "\n",
    "    # get plan start date\n",
    "    for country in output_data.Country.unique():\n",
    "        for ix, row in output_data[output_data['Country']==country].iterrows():\n",
    "            plan_start_date = row['Plan start date']\n",
    "            try:\n",
    "                activity_start_month_number = int(row['Planned activity start date'])\n",
    "                activity_end_month_number = int(row['Planned activity end date'])\n",
    "                activity_start_date = plan_start_date + timedelta(days=(activity_start_month_number-1)*31)\n",
    "                activity_end_date = plan_start_date + timedelta(days=activity_end_month_number*31)\n",
    "                output_data.at[ix, 'Planned activity start date'] = str(activity_start_date.date())\n",
    "                output_data.at[ix, 'Planned activity end date'] = str(activity_end_date.date())\n",
    "            except:\n",
    "                output_data.at[ix, 'Planned activity start date'] = ''\n",
    "                output_data.at[ix, 'Planned activity end date'] = ''\n",
    "                \n",
    "    output_data = output_data.drop(columns=['Plan start date'])\n",
    "            \n",
    "    # save output data\n",
    "    output_data.to_excel('matrix_filled.xlsx', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "East Asia missing tables\n",
      "Pacific missing tables\n",
      "Sth Asia missing tables\n",
      "Sth East Asia missing tables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\text\\lib\\site-packages\\ipykernel_launcher.py:66: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fiji has no target people\n",
      "Indonesia has no target people\n",
      "Indonesia has no target people\n",
      "Indonesia has no target people\n",
      "Lao PDR has no target people\n",
      "Lao PDR has no target people\n",
      "Lao PDR has no target people\n",
      "Marshall Islands has no target people\n",
      "Mongolia has no target people\n",
      "Nepal has no target people\n",
      "Nepal has no target people\n",
      "Nepal has no target people\n",
      "Papua New Guinea has no target people\n",
      "Philippines has no target people\n",
      "Solomon Islands has no target people\n",
      "Timor Leste has no target people\n",
      "Vanuatu has no target people\n",
      "Vanuatu has no target people\n",
      "Viet Nam has no target people\n",
      "Viet Nam has no target people\n"
     ]
    }
   ],
   "source": [
    "# prepare dataframe\n",
    "output_data = pd.read_excel('Matrix for data analysis from GO.xlsx')\n",
    "output_data.drop(output_data.index, inplace=True)\n",
    "# output_data = pd.read_excel('matrix_filled_temp.xlsx')\n",
    "output_data.to_excel('matrix_filled.xlsx', index=False)\n",
    "\n",
    "# do the magic\n",
    "# ExtractTxtAndTables()\n",
    "ParseTablesExtractActivities()\n",
    "ParseTxtExtractExtraInfoSector()\n",
    "ParseFirstPage()\n",
    "AdjustDates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to output, which is ignored by git, so that we are data responsible\n",
    "os.rename('matrix_filled.xlsx', 'Output/matrix_filled.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_conda",
   "language": "python",
   "name": "text_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
