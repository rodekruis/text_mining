{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from io import StringIO\n",
    "import os\n",
    "import codecs\n",
    "import re \n",
    "import camelot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sectors = ['Livelihoods and basic needs', 'Protection, Gender & Inclusion', 'Health', 'WASH', 'Migration']\n",
    "\n",
    "# map sectors to naming convention used in \"IFRC GO Matrix\"\n",
    "sector_map = {'Livelihoods and basic needs': 'Livelihoods and basic needs',\n",
    "              'WASH': 'WASH',\n",
    "              'Health': 'Health',\n",
    "              'Protection, Gender & Inclusion': 'PGI',\n",
    "              'Migration': 'Migration'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractTxtAndTables():\n",
    "    for country in os.listdir('Approved Plans'):\n",
    "#         # Test only on Cook Islands\n",
    "#         if country != 'Cook Islands':\n",
    "#             continue\n",
    "\n",
    "        for file in os.listdir('Approved Plans/'+country):\n",
    "\n",
    "            if file.startswith('MDR') and file.endswith('pdf'):\n",
    "                output_string = StringIO()\n",
    "                with open('Approved Plans/'+country+'/'+file, 'rb') as fh:\n",
    "                    parser = PDFParser(fh)\n",
    "                    doc = PDFDocument(parser)\n",
    "                    rsrcmgr = PDFResourceManager()\n",
    "                    device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
    "                    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "                    landscapepages = list()\n",
    "                    for ix, page in enumerate(PDFPage.create_pages(doc)):\n",
    "                        # only pages with landscape orientation\n",
    "                        if page.cropbox[2] < 800:\n",
    "                            continue\n",
    "                        interpreter.process_page(page)\n",
    "                        # count landscape page \n",
    "                        landscapepages.append(ix+1)\n",
    "                    \n",
    "                    landscapepages = str(landscapepages)\n",
    "                    landscapepages = landscapepages[1:-1]\n",
    "                    \n",
    "                    # find all tables on the landscape pages and create excel tables\n",
    "                    foundtables = camelot.read_pdf('Approved Plans/'+country+'/'+file, pages=landscapepages)\n",
    "                    for i in range(len(foundtables)):\n",
    "                        foundtables[i].to_excel('Approved Plans/'+country+'/'+'Table_test'+str(i)+'.xlsx')\n",
    "                        \n",
    "                    file1 = codecs.open('Approved Plans/'+country+'/'+file.split('.')[0]+'.txt', \"w\", \"utf-8\")  # write mode\n",
    "                    file1.write(output_string.getvalue())\n",
    "                    file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ParseTablesExtractActivities():\n",
    "    \n",
    "    for country in os.listdir('Approved Plans'):\n",
    "#         # Test only on Cook Islands\n",
    "#         if country != 'Palau':\n",
    "#             continue\n",
    "\n",
    "        # merge all tables\n",
    "        table_all = pd.DataFrame()\n",
    "        for table in [x for x in os.listdir('Approved Plans/'+country) if x.endswith('xlsx')]:\n",
    "                table = pd.read_excel('Approved Plans/'+country+'/'+table)\n",
    "                table_all = pd.concat([table_all, table])\n",
    "        table_all = table_all.rename(columns={0: 'code', 1: 'text'})\n",
    "        table_all = table_all.reset_index()\n",
    "        \n",
    "        if table_all.empty:\n",
    "            print(country, 'missing tables')\n",
    "            continue\n",
    "\n",
    "        # specify sector in each table entry\n",
    "        table_all['sector'] = ''\n",
    "        sector_active = ''\n",
    "        for ix, row in table_all.iterrows():\n",
    "            for sector in sectors:\n",
    "                search = sector + ' Outcome'\n",
    "                try:\n",
    "                    if search.lower() in row.text.lower() and 'P&B' in row.code:\n",
    "                        sector_active = sector\n",
    "                    else:\n",
    "                        continue\n",
    "                except:\n",
    "                    pass\n",
    "            table_all.at[ix, 'sector'] = sector_active\n",
    "        # print results\n",
    "        # for sector in table_all.sector.unique():\n",
    "        #     print(table_all[table_all.sector == sector].head())\n",
    "\n",
    "        # get activities\n",
    "        table_activities = table_all.dropna(subset=['code'])\n",
    "        table_activities = table_activities[table_activities.code.str.contains('AP')]\n",
    "        \n",
    "        # if some activities don't have a sector, assign nearest\n",
    "        if any(table_activities.sector == ''):\n",
    "            print('ERROR ({}): sector not found for some activities, skipping country'.format(country))\n",
    "            continue\n",
    "\n",
    "        # load output_data\n",
    "        output_data = pd.read_excel('matrix_filled.xlsx')\n",
    "\n",
    "        # fill output_data\n",
    "        for ix, row in table_activities.iterrows():\n",
    "            data_entry = pd.Series({'Country': country,\n",
    "                                    sector_map[row['sector']]: row['text']\n",
    "                                   })\n",
    "            output_data = output_data.append(data_entry, ignore_index=True)\n",
    "\n",
    "        # save output data\n",
    "        output_data.to_excel('matrix_filled.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ParseTxtExtractExtraInfoSector():\n",
    "    \n",
    "    sectors_txt = sectors\n",
    "    sectors_txt.append('Health and WASH') # some plans (e.g. Philippines) merge the two sectors\n",
    "    \n",
    "    for country in os.listdir('Approved Plans'):\n",
    "#         # Test only on Cook Islands\n",
    "#         if country != 'Cook Islands':\n",
    "#             continue\n",
    "\n",
    "        for file in os.listdir('Approved Plans/'+country):\n",
    "\n",
    "            if file.startswith('MDR') and file.endswith('txt'):\n",
    "                \n",
    "                # read txt file\n",
    "                file1 = codecs.open('Approved Plans/' + country + '/' + file.split('.')[0] + '.txt', \"r\",\n",
    "                                    \"utf-8\")  # write mode\n",
    "                text = file1.read()\n",
    "                \n",
    "                # get detailed operational plan\n",
    "                text = re.split(r\"(.*)Detailed Operational Plan\", text, re.MULTILINE | re.DOTALL)[-1]\n",
    "                \n",
    "                # loop over sectors and extract extra info\n",
    "                info_sectors = {}\n",
    "                \n",
    "                for sector in sectors_txt:\n",
    "                    if sector == 'Protection, Gender & Inclusion':\n",
    "                        sector_re = 'Protection, Gender and Inclusion'\n",
    "                    elif sector == 'WASH':\n",
    "                        sector_re = 'Water, sanitation and hygiene'\n",
    "                    else:\n",
    "                        sector_re = sector\n",
    "                        \n",
    "                    text_sector = re.split(sector_re+' \\nPeople', text, re.MULTILINE | re.DOTALL)\n",
    "                    \n",
    "                    if len(text_sector)==1:\n",
    "                        continue\n",
    "                    text_sector = text_sector[1]\n",
    "                    \n",
    "                    for line in re.split(r\"\\n\", text_sector, re.MULTILINE | re.DOTALL)[:10]:\n",
    "                        if 'targeted:' in line:\n",
    "                            peop_target = re.findall(r\"[0-9,]+\", line)[0]\n",
    "                        if 'Requirements (CHF):' in line:\n",
    "                            budget = re.findall(r\"[0-9,]+\", line)[0]\n",
    "                            \n",
    "                    if sector != 'Health and WASH':\n",
    "                        info_sectors[sector] = {'Number of targeted (if applicable)': peop_target, 'Funding': budget}\n",
    "                    else:\n",
    "                        info_sectors['Health'] = {'Number of targeted (if applicable)': peop_target, 'Funding': budget}\n",
    "                        info_sectors['WASH'] = {'Number of targeted (if applicable)': peop_target, 'Funding': budget}\n",
    "                    \n",
    "        # load output_data\n",
    "        output_data = pd.read_excel('matrix_filled.xlsx')\n",
    "\n",
    "        # fill output_data\n",
    "        for sector, infos in info_sectors.items():\n",
    "            for field, number in infos.items():\n",
    "                output_data.at[output_data[output_data['Country']==country][~output_data[sector_map[sector]].isna()].index, field] = number\n",
    "\n",
    "        # save output data\n",
    "        output_data.to_excel('matrix_filled.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "East Asia missing tables\n",
      "Pacific missing tables\n",
      "ERROR (Palau): sector not found for some activities, skipping country\n",
      "Sth Asia missing tables\n",
      "Sth East Asia missing tables\n",
      "Livelihoods and basic needs {'Number of targeted (if applicable)': '504,000', 'Funding': '7,185,679'}\n",
      "Protection, Gender & Inclusion {'Number of targeted (if applicable)': '150,000', 'Funding': '298,200'}\n",
      "Health {'Number of targeted (if applicable)': '2,042,500', 'Funding': '4,500,001'}\n",
      "WASH {'Number of targeted (if applicable)': '190,000', 'Funding': '529,724'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\text\\lib\\site-packages\\ipykernel_launcher.py:59: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health {'Number of targeted (if applicable)': '500,000', 'Funding': '4,809,929'}\n",
      "Migration {'Number of targeted (if applicable)': '100,000', 'Funding': '182,617'}\n",
      "Protection, Gender & Inclusion {'Number of targeted (if applicable)': '6,000', 'Funding': '533'}\n",
      "Health {'Number of targeted (if applicable)': '6,000', 'Funding': '15,342'}\n",
      "Health {'Number of targeted (if applicable)': '2,823,747', 'Funding': '581,998'}\n",
      "WASH {'Number of targeted (if applicable)': '2,823,747', 'Funding': '581,998'}\n",
      "Health {'Number of targeted (if applicable)': '2,823,747', 'Funding': '581,998'}\n",
      "WASH {'Number of targeted (if applicable)': '2,823,747', 'Funding': '581,998'}\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-153-c079a278f39b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# ExtractTxtAndTables()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mParseTablesExtractActivities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mParseTxtExtractExtraInfoSector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-152-bdfc0b2dcb7e>\u001b[0m in \u001b[0;36mParseTxtExtractExtraInfoSector\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m                             \u001b[0mpeop_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"[0-9,]+\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[1;34m'Requirements (CHF):'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m                             \u001b[0mbudget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"[0-9,]+\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0msector\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'Health and WASH'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# prepare dataframe\n",
    "output_data = pd.read_excel('Matrix for data analysis from GO.xlsx')\n",
    "output_data.drop(output_data.index, inplace=True)\n",
    "output_data.to_excel('matrix_filled.xlsx')\n",
    "\n",
    "# do the magic\n",
    "# ExtractTxtAndTables()\n",
    "ParseTablesExtractActivities()\n",
    "ParseTxtExtractExtraInfoSector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to output, which is ignored by git, so that we are data responsible\n",
    "os.rename('matrix_filled.xlsx', 'Output/matrix_filled.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_conda",
   "language": "python",
   "name": "text_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
